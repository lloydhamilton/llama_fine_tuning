{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:59:08.611620Z",
     "start_time": "2025-05-07T11:59:03.117582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, TextStreamer, QuantoConfig\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"squad\", split=\"train\")\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "base_model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "quant_config = QuantoConfig(weights=\"int8\")\n",
    "\n",
    "def fetch_model(is_quant: bool=False):\n",
    "    config = dict(\n",
    "        pretrained_model_name_or_path=base_model_path,\n",
    "        return_dict=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        # torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=quant_config,\n",
    "    )\n",
    "    if is_quant:\n",
    "        quant_cfg = {\n",
    "            \"quantization_config\": quant_config,\n",
    "        }\n",
    "        config = config | quant_cfg\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(**config)\n",
    "    if model.config.pad_token_id is None:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    return model\n",
    "\n",
    "def get_trainable_params(model) -> None:\n",
    "    \"\"\"\n",
    "    Get the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {params}\")\n",
    "\n",
    "quant_model = fetch_model(is_quant=True)\n",
    "base_model = fetch_model(is_quant=False)"
   ],
   "id": "2bfbd7d022ab5f94",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:59:24.072703Z",
     "start_time": "2025-05-07T11:59:24.070497Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.config._name_or_path",
   "id": "7be58e399212e5fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-llama/Llama-3.2-1B-Instruct'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:21.103072Z",
     "start_time": "2025-05-07T08:38:21.093983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model,\n",
    "    tokenizer=tokenizer,\n",
    "    # torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ],
   "id": "24f7732435f186c4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:21.972898Z",
     "start_time": "2025-05-07T08:38:21.970813Z"
    }
   },
   "cell_type": "code",
   "source": "get_trainable_params(base_model)",
   "id": "4d78216925069d8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 262735872\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:22.533455Z",
     "start_time": "2025-05-07T08:38:22.531070Z"
    }
   },
   "cell_type": "code",
   "source": "get_trainable_params(quant_model)",
   "id": "44bbea068639871f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 262735872\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:33.579471Z",
     "start_time": "2025-05-07T08:38:33.476099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import (\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\"k_proj\",\"v_proj\",\n",
    "        \"o_proj\", \"gate_proj\", \"up_proj\",\n",
    "        \"down_proj\"\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "lora_base_model = prepare_model_for_kbit_training(base_model)\n",
    "lora_base_model = get_peft_model(lora_base_model, lora_config)"
   ],
   "id": "6093d2dc889c18b6",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:41.534907Z",
     "start_time": "2025-05-07T08:38:41.530373Z"
    }
   },
   "cell_type": "code",
   "source": "get_trainable_params(lora_base_model)",
   "id": "b4bb9a9b8c6febb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 11272192\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:42.766902Z",
     "start_time": "2025-05-07T08:38:42.764941Z"
    }
   },
   "cell_type": "code",
   "source": "get_trainable_params(quant_model)",
   "id": "b4a0126320ec4ab6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 262735872\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:39:20.114895Z",
     "start_time": "2025-05-07T08:39:20.112945Z"
    }
   },
   "cell_type": "code",
   "source": "11272192/262735872",
   "id": "490c3aedb402a5eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04290313277054151"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:39:58.018197Z",
     "start_time": "2025-05-07T08:39:49.380052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Who is Vincent van Gogh?\"}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs = pipe(prompt, max_new_tokens=120, do_sample=True)\n",
    "\n",
    "print(outputs[0][\"generated_text\"])"
   ],
   "id": "1c6e90152020f2d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 07 May 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who is Vincent van Gogh?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Vincent Willem van Gogh (1853-1890) was a Dutch post-impressionist painter. He is widely regarded as one of the most influential and iconic artists of all time. Born in Groot-Zundert, Netherlands, Van Gogh was the eldest son of a Protestant pastor and grew up in a devout Christian household.\n",
      "\n",
      "Van Gogh's early life was marked by struggles with mental illness, poverty, and hardship. He began his artistic training in the Netherlands, studying art in the Netherlands and later in Paris. He became known for his bold and expressive paintings, which often\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:40:41.345694Z",
     "start_time": "2025-05-07T08:40:09.954519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a skilled Python developer specializing in database management and optimization.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm experiencing a sorting issue in my database. Could you please provide Python code to help resolve this problem?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs = pipe(prompt, max_new_tokens=512, do_sample=True)\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        outputs[0][\"generated_text\"].split(\n",
    "            \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "        )[1]\n",
    "    )\n",
    ")"
   ],
   "id": "b58e988a29eacb92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\n\nI can help you with that. The problem you're experiencing is likely due to a bug in the sorting algorithm you're using. Here's a Python solution using the built-in `sorted()` function with a custom key function that handles your specific case:\n\n### Problem: Sorting a List of Dictionaries\n\nLet's say you have a list of dictionaries and you want to sort them based on a specific key.\n\n### Solution\n\n```python\ndef custom_sort_key(dictionary):\n    \"\"\"\n    Custom key function to sort a dictionary based on a specific key.\n    \n    Args:\n        dictionary (dict): The dictionary to be sorted.\n    \n    Returns:\n        tuple: A tuple containing the index of the key and the value.\n    \"\"\"\n    return (dictionary[key], dictionary[key].lower())\n\n# Example usage:\ndata = [\n    {\"name\": \"John\", \"age\": 25, \"city\": \"New York\"},\n    {\"name\": \"Alice\", \"age\": 30, \"city\": \"Los Angeles\"},\n    {\"name\": \"Bob\", \"age\": 20, \"city\": \"Chicago\"}\n]\n\n# Sort the list of dictionaries\nsorted_data = sorted(data, key=custom_sort_key)\n\n# Print the sorted list\nfor item in sorted_data:\n    print(item)\n```\n\n### Explanation\n\nIn this code:\n\n*   We define a custom key function `custom_sort_key` that takes a dictionary as an argument and returns a tuple containing the index of the key and the value.\n*   We use the `sorted()` function with the `key` argument set to our custom key function. This tells Python to sort the list based on the values returned by the custom key function.\n*   We apply this custom key function to each item in the list, which sorts the list based on the values of the specified key.\n\n### Optimizations\n\nIf your list of dictionaries is very large, sorting it can be inefficient. In such cases, you can use the `sorted()` function with a `key` function that returns a lambda function that calculates the index of the key. This approach is faster than using a list comprehension with `sorted()`.\n\n```python\ndef custom_sort_key(index, value):\n    \"\"\"\n    Custom key function to sort a dictionary based on a specific key.\n    \n    Args:\n        index (int): The index of the key.\n        value: The value to be used for sorting.\n    \n    Returns:\n        tuple: A tuple containing the index of the key and the value.\n    \"\"\"\n    return (index,"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:41:09.624906Z",
     "start_time": "2025-05-07T08:41:09.620436Z"
    }
   },
   "cell_type": "code",
   "source": "data[\"train\"][0]",
   "id": "347ea2e4fcc2b639",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:41:12.462138Z",
     "start_time": "2025-05-07T08:41:12.306828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_chat_template(example):\n",
    "    answer = example['answers']['text']\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": example['question']},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return {\"prompt\": prompt}\n",
    "\n",
    "templated_dataset = data.map(apply_chat_template)"
   ],
   "id": "9b4588810dcdccb6",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:52:38.273991Z",
     "start_time": "2025-05-07T11:52:35.747470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "def apply_chat_template(\n",
    "        input_dataset: dict, tokeniser: PreTrainedTokenizerFast\n",
    ") -> dict:\n",
    "    \"\"\"Preprocess the input dataset to fit expected format.\n",
    "\n",
    "    See: https://huggingface.co/docs/trl/en/sft_trainer for details.\n",
    "    \"\"\"\n",
    "    answer = input_dataset['answers']['text']\n",
    "    message_template = [\n",
    "        {\"role\": \"system\", \"content\": input_dataset['context']},\n",
    "        {\"role\": \"user\", \"content\": input_dataset['question'][0]},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "    # messages = tokeniser.apply_chat_template(\n",
    "    #     message_template, tokenize=False, add_generation_prompt=True\n",
    "    # )\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "def apply_message_template(\n",
    "    input_dataset: dict\n",
    ") -> dict:\n",
    "    \"\"\"Preprocess the input dataset to fit expected format.\n",
    "\n",
    "    See: https://huggingface.co/docs/trl/en/sft_trainer for details.\n",
    "    \"\"\"\n",
    "    answer = input_dataset['answers']['text']\n",
    "    if isinstance(input_dataset['answers']['text'], list):\n",
    "        answer = input_dataset['answers']['text'][0]\n",
    "    message_template = [\n",
    "        {\"role\": \"system\", \"content\": input_dataset['context']},\n",
    "        {\"role\": \"user\", \"content\": input_dataset['question']},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "    return {\"messages\": message_template}\n",
    "\n",
    "templated_dataset = data.map(apply_message_template)"
   ],
   "id": "3b33a32a01a8fa0a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 87599/87599 [00:02<00:00, 34745.72 examples/s]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:52:38.280245Z",
     "start_time": "2025-05-07T11:52:38.278144Z"
    }
   },
   "cell_type": "code",
   "source": "templated_dataset[0]",
   "id": "f7c648bcf8662811",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]},\n",
       " 'messages': [{'content': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Saint Bernadette Soubirous', 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:58:33.078578Z",
     "start_time": "2025-05-07T11:58:33.064575Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "db8ae49fb6740633",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mbase_model\u001B[49m.config._name_or_path\n",
      "\u001B[31mNameError\u001B[39m: name 'base_model' is not defined"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:41:21.655863Z",
     "start_time": "2025-05-07T08:41:18.557176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenise the prompts\n",
    "def tokenize_function(example):\n",
    "    tokens = tokenizer(\n",
    "        example['prompt'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    # Set padding token labels to -100 to ignore them in loss calculation\n",
    "    tokens['labels'] = [\n",
    "        -100 if token == tokenizer.pad_token_id else token for token in tokens['input_ids']\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "tokenised_dataset = templated_dataset.map(tokenize_function)\n",
    "tokenised_dataset = tokenised_dataset.remove_columns([\"title\", \"context\", \"question\", \"answers\", \"prompt\"])"
   ],
   "id": "d16dcc2e5d39ea62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10570/10570 [00:02<00:00, 3587.33 examples/s]\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:41:22.379579Z",
     "start_time": "2025-05-07T08:41:22.378038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # https://www.mercity.ai/blog-post/guide-to-fine-tuning-llms-with-lora-and-qlora\n",
    "# # https://huggingface.co/docs/diffusers/en/quantization/quanto\n",
    "# for name, module in model.named_modules(): # https://www.datacamp.com/tutorial/fine-tuning-llama-3-2\n",
    "#     print(f\"name: {name}\")\n",
    "#     print(f\"module: {module}\")\n"
   ],
   "id": "90175f498ffc230f",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:17:04.941939Z",
     "start_time": "2025-05-07T07:14:46.652530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "lora_base_model.train()\n",
    "training_args = SFTConfig(\n",
    "    output_dir = \"cp\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    eval_accumulation_steps = 8,\n",
    "    # optim = \"paged_adamw_32bit\",\n",
    "    save_steps = 10,\n",
    "    logging_steps = 10,\n",
    "    learning_rate = 5e-5,\n",
    "    max_grad_norm = 0.3,\n",
    "    max_steps = 50,\n",
    "    warmup_ratio = 0.03,\n",
    "    eval_strategy=\"steps\",\n",
    "    lr_scheduler_type = \"linear\",\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    model=lora_base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_dataset[\"train\"],\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=lora_base_model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenised_dataset[\"train\"],\n",
    "#     eval_dataset=tokenised_dataset[\"validation\"],\n",
    "#     tokenizer=tokenizer)\n",
    "#\n",
    "# # Train the model\n",
    "# trainer.train()\n",
    "#\n",
    "# # Save the model and tokenizer\n",
    "# trainer.save_model(\"./fine-tuned-model\")\n",
    "# tokenizer.save_pretrained(\"./fine-tuned-model\")"
   ],
   "id": "c5e8e4cc98d8b052",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/ipykernel_73868/1483521713.py:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The following columns in the training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have been ignored: id. If id are not expected by `LlamaForCausalLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 87,599\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 20\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 20\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8,760\n",
      "  Number of trainable parameters = 1,235,814,400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='8760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  40/8760 02:11 < 8:21:49, 0.29 it/s, Epoch 0.01/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     22\u001B[39m trainer = Trainer(\n\u001B[32m     23\u001B[39m     model=model,\n\u001B[32m     24\u001B[39m     args=training_args,\n\u001B[32m     25\u001B[39m     train_dataset=tokenised_dataset[\u001B[33m\"\u001B[39m\u001B[33mtrain\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     26\u001B[39m     eval_dataset=tokenised_dataset[\u001B[33m\"\u001B[39m\u001B[33mvalidation\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     27\u001B[39m     tokenizer=tokenizer)\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Save the model and tokenizer\u001B[39;00m\n\u001B[32m     33\u001B[39m trainer.save_model(\u001B[33m\"\u001B[39m\u001B[33m./fine-tuned-model\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/transformers/trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2246\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2250\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/transformers/trainer.py:2560\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2553\u001B[39m context = (\n\u001B[32m   2554\u001B[39m     functools.partial(\u001B[38;5;28mself\u001B[39m.accelerator.no_sync, model=model)\n\u001B[32m   2555\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m i != \u001B[38;5;28mlen\u001B[39m(batch_samples) - \u001B[32m1\u001B[39m\n\u001B[32m   2556\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001B[32m   2557\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m contextlib.nullcontext\n\u001B[32m   2558\u001B[39m )\n\u001B[32m   2559\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[32m-> \u001B[39m\u001B[32m2560\u001B[39m     tr_loss_step = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2562\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2563\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   2564\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[32m   2565\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch.isinf(tr_loss_step))\n\u001B[32m   2566\u001B[39m ):\n\u001B[32m   2567\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   2568\u001B[39m     tr_loss = tr_loss + tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/transformers/trainer.py:3782\u001B[39m, in \u001B[36mTrainer.training_step\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m   3779\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001B[32m   3780\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mscale_wrt_gas\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3782\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maccelerator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3784\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss.detach()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/accelerate/accelerator.py:2454\u001B[39m, in \u001B[36mAccelerator.backward\u001B[39m\u001B[34m(self, loss, **kwargs)\u001B[39m\n\u001B[32m   2452\u001B[39m     \u001B[38;5;28mself\u001B[39m.lomo_backward(loss, learning_rate)\n\u001B[32m   2453\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2454\u001B[39m     \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:20:03.370872Z",
     "start_time": "2025-05-07T07:20:03.283424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "path = \"raw_data/ConvFinQA/train.json\"\n",
    "with open(path, \"r\") as file:\n",
    "    data = json.load(file)"
   ],
   "id": "ef48d34bb81dcb54",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:20:13.480480Z",
     "start_time": "2025-05-07T07:20:13.477732Z"
    }
   },
   "cell_type": "code",
   "source": "data[0]",
   "id": "5a755aafa8aa9331",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_text': ['26 | 2009 annual report in fiscal 2008 , revenues in the credit union systems and services business segment increased 14% ( 14 % ) from fiscal 2007 .',\n",
       "  'all revenue components within the segment experienced growth during fiscal 2008 .',\n",
       "  'license revenue generated the largest dollar growth in revenue as episys ae , our flagship core processing system aimed at larger credit unions , experienced strong sales throughout the year .',\n",
       "  'support and service revenue , which is the largest component of total revenues for the credit union segment , experienced 34 percent growth in eft support and 10 percent growth in in-house support .',\n",
       "  'gross profit in this business segment increased $ 9344 in fiscal 2008 compared to fiscal 2007 , due primarily to the increase in license revenue , which carries the highest margins .',\n",
       "  'liquidity and capital resources we have historically generated positive cash flow from operations and have generally used funds generated from operations and short-term borrowings on our revolving credit facility to meet capital requirements .',\n",
       "  'we expect this trend to continue in the future .',\n",
       "  'the company 2019s cash and cash equivalents increased to $ 118251 at june 30 , 2009 from $ 65565 at june 30 , 2008 .',\n",
       "  'the following table summarizes net cash from operating activities in the statement of cash flows : 2009 2008 2007 .'],\n",
       " 'post_text': ['year ended june 30 , cash provided by operations increased $ 25587 to $ 206588 for the fiscal year ended june 30 , 2009 as compared to $ 181001 for the fiscal year ended june 30 , 2008 .',\n",
       "  'this increase is primarily attributable to a decrease in receivables compared to the same period a year ago of $ 21214 .',\n",
       "  'this decrease is largely the result of fiscal 2010 annual software maintenance billings being provided to customers earlier than in the prior year , which allowed more cash to be collected before the end of the fiscal year than in previous years .',\n",
       "  'further , we collected more cash overall related to revenues that will be recognized in subsequent periods in the current year than in fiscal 2008 .',\n",
       "  'cash used in investing activities for the fiscal year ended june 2009 was $ 59227 and includes $ 3027 in contingent consideration paid on prior years 2019 acquisitions .',\n",
       "  'cash used in investing activities for the fiscal year ended june 2008 was $ 102148 and includes payments for acquisitions of $ 48109 , plus $ 1215 in contingent consideration paid on prior years 2019 acquisitions .',\n",
       "  'capital expenditures for fiscal 2009 were $ 31562 compared to $ 31105 for fiscal 2008 .',\n",
       "  'cash used for software development in fiscal 2009 was $ 24684 compared to $ 23736 during the prior year .',\n",
       "  'net cash used in financing activities for the current fiscal year was $ 94675 and includes the repurchase of 3106 shares of our common stock for $ 58405 , the payment of dividends of $ 26903 and $ 13489 net repayment on our revolving credit facilities .',\n",
       "  'cash used in financing activities was partially offset by proceeds of $ 3773 from the exercise of stock options and the sale of common stock ( through the employee stock purchase plan ) and $ 348 excess tax benefits from stock option exercises .',\n",
       "  'during fiscal 2008 , net cash used in financing activities for the fiscal year was $ 101905 and includes the repurchase of 4200 shares of our common stock for $ 100996 , the payment of dividends of $ 24683 and $ 429 net repayment on our revolving credit facilities .',\n",
       "  'cash used in financing activities was partially offset by proceeds of $ 20394 from the exercise of stock options and the sale of common stock and $ 3809 excess tax benefits from stock option exercises .',\n",
       "  'beginning during fiscal 2008 , us financial markets and many of the largest us financial institutions have been shaken by negative developments in the home mortgage industry and the mortgage markets , and particularly the markets for subprime mortgage-backed securities .',\n",
       "  'since that time , these and other such developments have resulted in a broad , global economic downturn .',\n",
       "  'while we , as is the case with most companies , have experienced the effects of this downturn , we have not experienced any significant issues with our current collection efforts , and we believe that any future impact to our liquidity will be minimized by cash generated by recurring sources of revenue and due to our access to available lines of credit. .'],\n",
       " 'filename': 'JKHY/2009/page_28.pdf',\n",
       " 'table_ori': [['', 'Year ended June 30, 2009'],\n",
       "  ['2008', '2007'],\n",
       "  ['Net income', '$103,102', '$104,222', '$104,681'],\n",
       "  ['Non-cash expenses', '74,397', '70,420', '56,348'],\n",
       "  ['Change in receivables', '21,214', '(2,913)', '(28,853)'],\n",
       "  ['Change in deferred revenue', '21,943', '5,100', '24,576'],\n",
       "  ['Change in other assets and liabilities', '(14,068)', '4,172', '17,495'],\n",
       "  ['Net cash from operating activities', '$206,588', '$181,001', '$174,247']],\n",
       " 'table': [['2008',\n",
       "   'year ended june 30 2009 2008',\n",
       "   'year ended june 30 2009 2008',\n",
       "   'year ended june 30 2009'],\n",
       "  ['net income', '$ 103102', '$ 104222', '$ 104681'],\n",
       "  ['non-cash expenses', '74397', '70420', '56348'],\n",
       "  ['change in receivables', '21214', '-2913 ( 2913 )', '-28853 ( 28853 )'],\n",
       "  ['change in deferred revenue', '21943', '5100', '24576'],\n",
       "  ['change in other assets and liabilities',\n",
       "   '-14068 ( 14068 )',\n",
       "   '4172',\n",
       "   '17495'],\n",
       "  ['net cash from operating activities', '$ 206588', '$ 181001', '$ 174247']],\n",
       " 'qa': {'question': 'what was the percentage change in the net cash from operating activities from 2008 to 2009',\n",
       "  'answer': '14.1%',\n",
       "  'explanation': '',\n",
       "  'ann_table_rows': [6],\n",
       "  'ann_text_rows': [],\n",
       "  'steps': [{'op': 'minus2-1',\n",
       "    'arg1': '206588',\n",
       "    'arg2': '181001',\n",
       "    'res': '25587'},\n",
       "   {'op': 'divide2-2', 'arg1': '#0', 'arg2': '181001', 'res': '14.1%'}],\n",
       "  'program': 'subtract(206588, 181001), divide(#0, 181001)',\n",
       "  'gold_inds': {'table_6': '2008 the net cash from operating activities of year ended june 30 2009 2008 is $ 206588 ; the net cash from operating activities of year ended june 30 2009 2008 is $ 181001 ; the net cash from operating activities of year ended june 30 2009 is $ 174247 ;'},\n",
       "  'exe_ans': 0.14136,\n",
       "  'program_re': 'divide(subtract(206588, 181001), 181001)'},\n",
       " 'id': 'Single_JKHY/2009/page_28.pdf-3',\n",
       " 'annotation': {'amt_table': \"<table class='wikitable'><tr><td>1</td><td>2008</td><td>year ended june 30 2009 2008</td><td>year ended june 30 2009 2008</td><td>year ended june 30 2009</td></tr><tr><td>2</td><td>net income</td><td>$ 103102</td><td>$ 104222</td><td>$ 104681</td></tr><tr><td>3</td><td>non-cash expenses</td><td>74397</td><td>70420</td><td>56348</td></tr><tr><td>4</td><td>change in receivables</td><td>21214</td><td>-2913 ( 2913 )</td><td>-28853 ( 28853 )</td></tr><tr><td>5</td><td>change in deferred revenue</td><td>21943</td><td>5100</td><td>24576</td></tr><tr><td>6</td><td>change in other assets and liabilities</td><td>-14068 ( 14068 )</td><td>4172</td><td>17495</td></tr><tr><td>7</td><td>net cash from operating activities</td><td>$ 206588</td><td>$ 181001</td><td>$ 174247</td></tr></table>\",\n",
       "  'amt_pre_text': '26 | 2009 annual report in fiscal 2008 , revenues in the credit union systems and services business segment increased 14% ( 14 % ) from fiscal 2007 . all revenue components within the segment experienced growth during fiscal 2008 . license revenue generated the largest dollar growth in revenue as episys ae , our flagship core processing system aimed at larger credit unions , experienced strong sales throughout the year . support and service revenue , which is the largest component of total revenues for the credit union segment , experienced 34 percent growth in eft support and 10 percent growth in in-house support . gross profit in this business segment increased $ 9344 in fiscal 2008 compared to fiscal 2007 , due primarily to the increase in license revenue , which carries the highest margins . liquidity and capital resources we have historically generated positive cash flow from operations and have generally used funds generated from operations and short-term borrowings on our revolving credit facility to meet capital requirements . we expect this trend to continue in the future . the company 2019s cash and cash equivalents increased to $ 118251 at june 30 , 2009 from $ 65565 at june 30 , 2008 . the following table summarizes net cash from operating activities in the statement of cash flows : 2009 2008 2007 .',\n",
       "  'amt_post_text': 'year ended june 30 , cash provided by operations increased $ 25587 to $ 206588 for the fiscal year ended june 30 , 2009 as compared to $ 181001 for the fiscal year ended june 30 , 2008 . this increase is primarily attributable to a decrease in receivables compared to the same period a year ago of $ 21214 . this decrease is largely the result of fiscal 2010 annual software maintenance billings being provided to customers earlier than in the prior year , which allowed more cash to be collected before the end of the fiscal year than in previous years . further , we collected more cash overall related to revenues that will be recognized in subsequent periods in the current year than in fiscal 2008 . cash used in investing activities for the fiscal year ended june 2009 was $ 59227 and includes $ 3027 in contingent consideration paid on prior years 2019 acquisitions . cash used in investing activities for the fiscal year ended june 2008 was $ 102148 and includes payments for acquisitions of $ 48109 , plus $ 1215 in contingent consideration paid on prior years 2019 acquisitions . capital expenditures for fiscal 2009 were $ 31562 compared to $ 31105 for fiscal 2008 . cash used for software development in fiscal 2009 was $ 24684 compared to $ 23736 during the prior year . net cash used in financing activities for the current fiscal year was $ 94675 and includes the repurchase of 3106 shares of our common stock for $ 58405 , the payment of dividends of $ 26903 and $ 13489 net repayment on our revolving credit facilities . cash used in financing activities was partially offset by proceeds of $ 3773 from the exercise of stock options and the sale of common stock ( through the employee stock purchase plan ) and $ 348 excess tax benefits from stock option exercises . during fiscal 2008 , net cash used in financing activities for the fiscal year was $ 101905 and includes the repurchase of 4200 shares of our common stock for $ 100996 , the payment of dividends of $ 24683 and $ 429 net repayment on our revolving credit facilities . cash used in financing activities was partially offset by proceeds of $ 20394 from the exercise of stock options and the sale of common stock and $ 3809 excess tax benefits from stock option exercises . beginning during fiscal 2008 , us financial markets and many of the largest us financial institutions have been shaken by negative developments in the home mortgage industry and the mortgage markets , and particularly the markets for subprime mortgage-backed securities . since that time , these and other such developments have resulted in a broad , global economic downturn . while we , as is the case with most companies , have experienced the effects of this downturn , we have not experienced any significant issues with our current collection efforts , and we believe that any future impact to our liquidity will be minimized by cash generated by recurring sources of revenue and due to our access to available lines of credit. .',\n",
       "  'original_program': 'subtract(206588, 181001), divide(A0, 181001)',\n",
       "  'step_list': ['Ask for number 206588',\n",
       "   'Ask for number 181001',\n",
       "   'subtract(206588, 181001)',\n",
       "   'divide(A0, 181001)'],\n",
       "  'answer_list': ['206588', '181001', 'A0', 'A1'],\n",
       "  'dialogue_break': ['what is the net cash from operating activities in 2009?',\n",
       "   'what about in 2008?',\n",
       "   'what is the difference?',\n",
       "   'what percentage change does this represent?'],\n",
       "  'turn_program_ori': ['206588',\n",
       "   '181001',\n",
       "   'subtract(206588, 181001)',\n",
       "   'subtract(206588, 181001), divide(#0, 181001)'],\n",
       "  'dialogue_break_ori': ['what is the net cash from operating activities in 2009?',\n",
       "   'what about in 2008?',\n",
       "   'what is the difference?',\n",
       "   'what percentage change does this represent?'],\n",
       "  'turn_program': ['206588',\n",
       "   '181001',\n",
       "   'subtract(206588, 181001)',\n",
       "   'subtract(206588, 181001), divide(#0, 181001)'],\n",
       "  'qa_split': [0, 0, 0, 0],\n",
       "  'exe_ans_list': [206588.0, 181001.0, 25587.0, 0.14136]}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:23:50.089416Z",
     "start_time": "2025-05-07T15:23:42.201039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import PeftModel\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "def load_lora_model(base_model_path, adapter_path):\n",
    "    # First load the base model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model_path,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "\n",
    "    # Then load the LoRA adapter weights\n",
    "    fine_tuned_model = PeftModel.from_pretrained(base_model, adapter_path)\n",
    "    return fine_tuned_model, base_model, tokenizer\n",
    "model_path = \"../cp/checkpoint-60\"  # Your output directory from training\n",
    "base_model_path = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "ft_model, base_model, tokeniser = load_lora_model(base_model_path, model_path)"
   ],
   "id": "de37e09ac2478192",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:06:58.096583Z",
     "start_time": "2025-05-07T15:06:55.403829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from datasets import load_dataset\n",
    "val_data = load_dataset(\"squad\")\n",
    "\n",
    "ft_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=ft_model,\n",
    "    tokenizer=tokeniser,\n",
    "    # torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "base_pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model,\n",
    "    tokenizer=tokeniser,\n",
    "    # torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ],
   "id": "eaa0084b0799db7e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n",
      "Device set to use mps\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T14:39:15.565801Z",
     "start_time": "2025-05-07T14:39:15.563031Z"
    }
   },
   "cell_type": "code",
   "source": "val_data[\"train\"][1]",
   "id": "3fc17ff10cc117a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f4190066117f',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'What is in front of the Notre Dame Main Building?',\n",
       " 'answers': {'text': ['a copper statue of Christ'], 'answer_start': [188]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:07:13.783144Z",
     "start_time": "2025-05-07T15:07:10.487498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is in front of the Notre Dame Main Building?\"}]\n",
    "\n",
    "prompt = tokeniser.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "with torch.no_grad():\n",
    "    outputs = base_pipe(prompt, max_new_tokens=120, do_sample=True)\n",
    "\n",
    "print(outputs[0][\"generated_text\"])"
   ],
   "id": "ebc3215a12ce5582",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 07 May 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is in front of the Notre Dame Main Building?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The front of the Notre Dame Main Building is the courtyard, with the famous \"Nightingale Bridge\" in front.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:07:15.122849Z",
     "start_time": "2025-05-07T15:07:13.875809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    outputs = ft_pipe(prompt, max_new_tokens=120, do_sample=True)\n",
    "\n",
    "print(outputs[0][\"generated_text\"])"
   ],
   "id": "f61f19aafffc88df",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 07 May 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What is in front of the Notre Dame Main Building?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I am unable to verify what is in front of the Notre Dame Main Building.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:07:18.113570Z",
     "start_time": "2025-05-07T15:07:18.109980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_assistant_response(output_text):\n",
    "    # Extract content after the assistant header\n",
    "    if \"<|start_header_id|>assistant<|end_header_id|>\" in output_text:\n",
    "        return output_text.split(\"<|start_header_id|>assistant<|end_header_id|>\")[1].strip()\n",
    "    return output_text\n",
    "\n",
    "extract_assistant_response(outputs[0][\"generated_text\"])"
   ],
   "id": "2cebdb15517a1c2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am unable to verify what is in front of the Notre Dame Main Building.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T15:24:33.412306Z",
     "start_time": "2025-05-07T15:23:55.382932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from mlflow.models import infer_signature\n",
    "import mlflow\n",
    "\n",
    "# last_run_id = mlflow.last_active_run().info.run_id\n",
    "# Save a tokenizer without padding because it is only needed for training\n",
    "tokenizer_no_pad = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-3B-Instruct\", add_bos_token=True\n",
    ")\n",
    "with mlflow.start_run():\n",
    "    # mlflow.log_params(self.lora_config.to_dict())\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model=dict(\n",
    "            model=base_model, tokenizer=tokenizer_no_pad\n",
    "        ),\n",
    "        artifact_path=\"model\",\n",
    "        signature=infer_signature(\n",
    "            model_input={\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is in front of the Notre Dame Main Building?\",\n",
    "            },\n",
    "        ),\n",
    "    )"
   ],
   "id": "e2135ddc7f11cbe0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "2025/05/07 16:24:32 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "[('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00025-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00025-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00025-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00025-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00020-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00020-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00020-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00020-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00018-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00018-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00018-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00018-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00017-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00017-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00017-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00017-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00012-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00012-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00012-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00012-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00005-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00005-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00005-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00005-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00016-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00016-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00016-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00016-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00013-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00013-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00013-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00013-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00024-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00024-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00024-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00024-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00019-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00019-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00019-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00019-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00021-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00021-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00021-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00021-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00001-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00001-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00001-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00001-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00004-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00004-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00004-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00004-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00007-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00007-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00007-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00007-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00002-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00002-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00002-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00002-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00008-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00008-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00008-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00008-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00022-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00022-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00022-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00022-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00027-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00027-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00027-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00027-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00028-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00028-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00028-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00028-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00010-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00010-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00010-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00010-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00015-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00015-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00015-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00015-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00009-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00009-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00009-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00009-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00006-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00006-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00006-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00006-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00003-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00003-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00003-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00003-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00011-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00011-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00011-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00011-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00029-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00029-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00029-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00029-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00014-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00014-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00014-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00014-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00023-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00023-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00023-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00023-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00026-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00026-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00026-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00026-of-00029.safetensors'\")]",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mError\u001B[39m                                     Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      6\u001B[39m tokenizer_no_pad = AutoTokenizer.from_pretrained(\n\u001B[32m      7\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmeta-llama/Llama-3.2-3B-Instruct\u001B[39m\u001B[33m\"\u001B[39m, add_bos_token=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m      8\u001B[39m )\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m mlflow.start_run():\n\u001B[32m     10\u001B[39m     \u001B[38;5;66;03m# mlflow.log_params(self.lora_config.to_dict())\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m     \u001B[43mmlflow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtransformers\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtransformers_model\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbase_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtokenizer_no_pad\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m        \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m        \u001B[49m\u001B[43msignature\u001B[49m\u001B[43m=\u001B[49m\u001B[43minfer_signature\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmodel_input\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrole\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m                \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcontent\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mWhat is in front of the Notre Dame Main Building?\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m            \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     21\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     22\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/mlflow/transformers/__init__.py:1022\u001B[39m, in \u001B[36mlog_model\u001B[39m\u001B[34m(transformers_model, artifact_path, processor, task, torch_dtype, model_card, inference_config, code_paths, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, conda_env, metadata, model_config, example_no_conversion, prompt_template, save_pretrained, prompts, **kwargs)\u001B[39m\n\u001B[32m    791\u001B[39m \u001B[38;5;129m@experimental\u001B[39m\n\u001B[32m    792\u001B[39m \u001B[38;5;129m@docstring_version_compatibility_warning\u001B[39m(integration_name=FLAVOR_NAME)\n\u001B[32m    793\u001B[39m \u001B[38;5;129m@format_docstring\u001B[39m(LOG_MODEL_PARAM_DOCS.format(package_name=FLAVOR_NAME))\n\u001B[32m   (...)\u001B[39m\u001B[32m    816\u001B[39m     **kwargs,\n\u001B[32m    817\u001B[39m ):\n\u001B[32m    818\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    819\u001B[39m \u001B[33;03m    Log a ``transformers`` object as an MLflow artifact for the current run. Note that\u001B[39;00m\n\u001B[32m    820\u001B[39m \u001B[33;03m    logging transformers models with custom code (i.e. models that require\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1020\u001B[39m \u001B[33;03m        kwargs: Additional arguments for :py:class:`mlflow.models.model.Model`\u001B[39;00m\n\u001B[32m   1021\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1022\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mModel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1023\u001B[39m \u001B[43m        \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1024\u001B[39m \u001B[43m        \u001B[49m\u001B[43mflavor\u001B[49m\u001B[43m=\u001B[49m\u001B[43msys\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodules\u001B[49m\u001B[43m[\u001B[49m\u001B[34;43m__name__\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Get the current module.\u001B[39;49;00m\n\u001B[32m   1025\u001B[39m \u001B[43m        \u001B[49m\u001B[43mregistered_model_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mregistered_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[43m        \u001B[49m\u001B[43mawait_registration_for\u001B[49m\u001B[43m=\u001B[49m\u001B[43mawait_registration_for\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1027\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1028\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtransformers_model\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtransformers_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1029\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprocessor\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprocessor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1030\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1031\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1032\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_card\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_card\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1033\u001B[39m \u001B[43m        \u001B[49m\u001B[43minference_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43minference_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1034\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconda_env\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconda_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1035\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcode_paths\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcode_paths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1036\u001B[39m \u001B[43m        \u001B[49m\u001B[43msignature\u001B[49m\u001B[43m=\u001B[49m\u001B[43msignature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1037\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_example\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_example\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1038\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# NB: We don't validate the serving input if the provided model is a path\u001B[39;49;00m\n\u001B[32m   1039\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# to a local checkpoint. This is because the purpose of supporting that\u001B[39;49;00m\n\u001B[32m   1040\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# input format is to avoid loading large model into memory. Serving input\u001B[39;49;00m\n\u001B[32m   1041\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# validation loads the model into memory and make prediction, which is\u001B[39;49;00m\n\u001B[32m   1042\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# expensive and can cause OOM errors.\u001B[39;49;00m\n\u001B[32m   1043\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalidate_serving_input\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtransformers_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1044\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpip_requirements\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpip_requirements\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1045\u001B[39m \u001B[43m        \u001B[49m\u001B[43mextra_pip_requirements\u001B[49m\u001B[43m=\u001B[49m\u001B[43mextra_pip_requirements\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1046\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1047\u001B[39m \u001B[43m        \u001B[49m\u001B[43mexample_no_conversion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexample_no_conversion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1048\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompt_template\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprompt_template\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1049\u001B[39m \u001B[43m        \u001B[49m\u001B[43msave_pretrained\u001B[49m\u001B[43m=\u001B[49m\u001B[43msave_pretrained\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1050\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1051\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1052\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/mlflow/models/model.py:921\u001B[39m, in \u001B[36mModel.log\u001B[39m\u001B[34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, **kwargs)\u001B[39m\n\u001B[32m    918\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m prompt \u001B[38;5;129;01min\u001B[39;00m prompts:\n\u001B[32m    919\u001B[39m         client.log_prompt(run_id, prompt)\n\u001B[32m--> \u001B[39m\u001B[32m921\u001B[39m \u001B[43mmlflow\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtracking\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfluent\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmlflow_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    923\u001B[39m \u001B[38;5;66;03m# if the model_config kwarg is passed in, then log the model config as an params\u001B[39;00m\n\u001B[32m    924\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m model_config := kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mmodel_config\u001B[39m\u001B[33m\"\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:1219\u001B[39m, in \u001B[36mlog_artifacts\u001B[39m\u001B[34m(local_dir, artifact_path, run_id)\u001B[39m\n\u001B[32m   1185\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1186\u001B[39m \u001B[33;03mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001B[39;00m\n\u001B[32m   1187\u001B[39m \u001B[33;03mthis method will create a new active run.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1216\u001B[39m \u001B[33;03m            mlflow.log_artifacts(tmp_dir, artifact_path=\"states\")\u001B[39;00m\n\u001B[32m   1217\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1218\u001B[39m run_id = run_id \u001B[38;5;129;01mor\u001B[39;00m _get_or_start_run().info.run_id\n\u001B[32m-> \u001B[39m\u001B[32m1219\u001B[39m \u001B[43mMlflowClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:2428\u001B[39m, in \u001B[36mMlflowClient.log_artifacts\u001B[39m\u001B[34m(self, run_id, local_dir, artifact_path)\u001B[39m\n\u001B[32m   2381\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mlog_artifacts\u001B[39m(\n\u001B[32m   2382\u001B[39m     \u001B[38;5;28mself\u001B[39m, run_id: \u001B[38;5;28mstr\u001B[39m, local_dir: \u001B[38;5;28mstr\u001B[39m, artifact_path: Optional[\u001B[38;5;28mstr\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   2383\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2384\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001B[39;00m\n\u001B[32m   2385\u001B[39m \n\u001B[32m   2386\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   2426\u001B[39m \n\u001B[32m   2427\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2428\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_tracking_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:964\u001B[39m, in \u001B[36mTrackingServiceClient.log_artifacts\u001B[39m\u001B[34m(self, run_id, local_dir, artifact_path)\u001B[39m\n\u001B[32m    955\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mlog_artifacts\u001B[39m(\u001B[38;5;28mself\u001B[39m, run_id, local_dir, artifact_path=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m    956\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001B[39;00m\n\u001B[32m    957\u001B[39m \n\u001B[32m    958\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    962\u001B[39m \n\u001B[32m    963\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m964\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_artifact_repo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/mlflow/store/artifact/local_artifact_repo.py:67\u001B[39m, in \u001B[36mLocalArtifactRepository.log_artifacts\u001B[39m\u001B[34m(self, local_dir, artifact_path)\u001B[39m\n\u001B[32m     65\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os.path.exists(artifact_dir):\n\u001B[32m     66\u001B[39m     mkdir(artifact_dir)\n\u001B[32m---> \u001B[39m\u001B[32m67\u001B[39m \u001B[43mshutil\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcopytree\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdst\u001B[49m\u001B[43m=\u001B[49m\u001B[43martifact_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdirs_exist_ok\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/shutil.py:600\u001B[39m, in \u001B[36mcopytree\u001B[39m\u001B[34m(src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001B[39m\n\u001B[32m    598\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m os.scandir(src) \u001B[38;5;28;01mas\u001B[39;00m itr:\n\u001B[32m    599\u001B[39m     entries = \u001B[38;5;28mlist\u001B[39m(itr)\n\u001B[32m--> \u001B[39m\u001B[32m600\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_copytree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mentries\u001B[49m\u001B[43m=\u001B[49m\u001B[43mentries\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[43m=\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdst\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msymlinks\u001B[49m\u001B[43m=\u001B[49m\u001B[43msymlinks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    601\u001B[39m \u001B[43m                 \u001B[49m\u001B[43mignore\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy_function\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcopy_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    602\u001B[39m \u001B[43m                 \u001B[49m\u001B[43mignore_dangling_symlinks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_dangling_symlinks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    603\u001B[39m \u001B[43m                 \u001B[49m\u001B[43mdirs_exist_ok\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdirs_exist_ok\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/shutil.py:554\u001B[39m, in \u001B[36m_copytree\u001B[39m\u001B[34m(entries, src, dst, symlinks, ignore, copy_function, ignore_dangling_symlinks, dirs_exist_ok)\u001B[39m\n\u001B[32m    552\u001B[39m         errors.append((src, dst, \u001B[38;5;28mstr\u001B[39m(why)))\n\u001B[32m    553\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m errors:\n\u001B[32m--> \u001B[39m\u001B[32m554\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m Error(errors)\n\u001B[32m    555\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m dst\n",
      "\u001B[31mError\u001B[39m: [('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00025-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00025-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00025-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00025-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00020-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00020-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00020-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00020-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00018-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00018-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00018-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00018-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00017-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00017-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00017-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00017-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00012-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00012-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00012-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00012-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00005-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00005-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00005-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00005-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00016-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00016-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00016-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00016-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00013-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00013-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00013-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00013-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00024-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00024-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00024-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00024-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00019-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00019-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00019-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00019-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00021-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00021-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00021-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00021-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00001-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00001-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00001-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00001-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00004-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00004-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00004-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00004-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00007-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00007-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00007-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00007-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00002-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00002-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00002-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00002-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00008-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00008-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00008-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00008-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00022-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00022-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00022-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00022-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00027-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00027-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00027-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00027-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00028-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00028-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00028-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00028-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00010-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00010-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00010-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00010-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00015-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00015-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00015-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00015-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00009-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00009-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00009-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00009-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00006-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00006-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00006-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00006-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00003-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00003-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00003-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00003-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00011-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00011-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00011-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00011-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00029-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00029-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00029-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00029-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00014-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00014-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00014-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00014-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00023-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00023-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00023-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00023-of-00029.safetensors'\"), ('/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00026-of-00029.safetensors', '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00026-of-00029.safetensors', \"[Errno 28] No space left on device: '/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/tmp0w_o8yr0/model/model/model-00026-of-00029.safetensors' -> '/Users/lloydhamilton/Documents/PersonalProjects.nosync/tomorro_llm_tech/src/mlruns/0/7610a39315d84ce19b4a5bae981d1b22/artifacts/model/model/model-00026-of-00029.safetensors'\")]"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8af94ab37fdd8fed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
