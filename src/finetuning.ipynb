{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:59:08.611620Z",
     "start_time": "2025-05-07T11:59:03.117582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, TextStreamer, QuantoConfig\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"squad\", split=\"train\")\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "base_model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "quant_config = QuantoConfig(weights=\"int8\")\n",
    "\n",
    "def fetch_model(is_quant: bool=False):\n",
    "    config = dict(\n",
    "        pretrained_model_name_or_path=base_model_path,\n",
    "        return_dict=True,\n",
    "        low_cpu_mem_usage=True,\n",
    "        # torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        quantization_config=quant_config,\n",
    "    )\n",
    "    if is_quant:\n",
    "        quant_cfg = {\n",
    "            \"quantization_config\": quant_config,\n",
    "        }\n",
    "        config = config | quant_cfg\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(**config)\n",
    "    if model.config.pad_token_id is None:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "    return model\n",
    "\n",
    "def get_trainable_params(model) -> None:\n",
    "    \"\"\"\n",
    "    Get the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total trainable parameters: {params}\")\n",
    "\n",
    "quant_model = fetch_model(is_quant=True)\n",
    "base_model = fetch_model(is_quant=False)"
   ],
   "id": "2bfbd7d022ab5f94",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:59:24.072703Z",
     "start_time": "2025-05-07T11:59:24.070497Z"
    }
   },
   "cell_type": "code",
   "source": "base_model.config._name_or_path",
   "id": "7be58e399212e5fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meta-llama/Llama-3.2-1B-Instruct'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:21.103072Z",
     "start_time": "2025-05-07T08:38:21.093983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model,\n",
    "    tokenizer=tokenizer,\n",
    "    # torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ],
   "id": "24f7732435f186c4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:21.972898Z",
     "start_time": "2025-05-07T08:38:21.970813Z"
    }
   },
   "cell_type": "code",
   "source": "get_trainable_params(base_model)",
   "id": "4d78216925069d8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 262735872\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:22.533455Z",
     "start_time": "2025-05-07T08:38:22.531070Z"
    }
   },
   "cell_type": "code",
   "source": "get_trainable_params(quant_model)",
   "id": "44bbea068639871f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 262735872\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:33.579471Z",
     "start_time": "2025-05-07T08:38:33.476099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft import (\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\"k_proj\",\"v_proj\",\n",
    "        \"o_proj\", \"gate_proj\", \"up_proj\",\n",
    "        \"down_proj\"\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "lora_base_model = prepare_model_for_kbit_training(base_model)\n",
    "lora_base_model = get_peft_model(lora_base_model, lora_config)"
   ],
   "id": "6093d2dc889c18b6",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:41.534907Z",
     "start_time": "2025-05-07T08:38:41.530373Z"
    }
   },
   "cell_type": "code",
   "source": "get_trainable_params(lora_base_model)",
   "id": "b4bb9a9b8c6febb5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 11272192\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:38:42.766902Z",
     "start_time": "2025-05-07T08:38:42.764941Z"
    }
   },
   "cell_type": "code",
   "source": "get_trainable_params(quant_model)",
   "id": "b4a0126320ec4ab6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 262735872\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:39:20.114895Z",
     "start_time": "2025-05-07T08:39:20.112945Z"
    }
   },
   "cell_type": "code",
   "source": "11272192/262735872",
   "id": "490c3aedb402a5eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04290313277054151"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:39:58.018197Z",
     "start_time": "2025-05-07T08:39:49.380052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Who is Vincent van Gogh?\"}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs = pipe(prompt, max_new_tokens=120, do_sample=True)\n",
    "\n",
    "print(outputs[0][\"generated_text\"])"
   ],
   "id": "1c6e90152020f2d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 07 May 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Who is Vincent van Gogh?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Vincent Willem van Gogh (1853-1890) was a Dutch post-impressionist painter. He is widely regarded as one of the most influential and iconic artists of all time. Born in Groot-Zundert, Netherlands, Van Gogh was the eldest son of a Protestant pastor and grew up in a devout Christian household.\n",
      "\n",
      "Van Gogh's early life was marked by struggles with mental illness, poverty, and hardship. He began his artistic training in the Netherlands, studying art in the Netherlands and later in Paris. He became known for his bold and expressive paintings, which often\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:40:41.345694Z",
     "start_time": "2025-05-07T08:40:09.954519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a skilled Python developer specializing in database management and optimization.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm experiencing a sorting issue in my database. Could you please provide Python code to help resolve this problem?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "outputs = pipe(prompt, max_new_tokens=512, do_sample=True)\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        outputs[0][\"generated_text\"].split(\n",
    "            \"<|start_header_id|>assistant<|end_header_id|>\"\n",
    "        )[1]\n",
    "    )\n",
    ")"
   ],
   "id": "b58e988a29eacb92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "\n\nI can help you with that. The problem you're experiencing is likely due to a bug in the sorting algorithm you're using. Here's a Python solution using the built-in `sorted()` function with a custom key function that handles your specific case:\n\n### Problem: Sorting a List of Dictionaries\n\nLet's say you have a list of dictionaries and you want to sort them based on a specific key.\n\n### Solution\n\n```python\ndef custom_sort_key(dictionary):\n    \"\"\"\n    Custom key function to sort a dictionary based on a specific key.\n    \n    Args:\n        dictionary (dict): The dictionary to be sorted.\n    \n    Returns:\n        tuple: A tuple containing the index of the key and the value.\n    \"\"\"\n    return (dictionary[key], dictionary[key].lower())\n\n# Example usage:\ndata = [\n    {\"name\": \"John\", \"age\": 25, \"city\": \"New York\"},\n    {\"name\": \"Alice\", \"age\": 30, \"city\": \"Los Angeles\"},\n    {\"name\": \"Bob\", \"age\": 20, \"city\": \"Chicago\"}\n]\n\n# Sort the list of dictionaries\nsorted_data = sorted(data, key=custom_sort_key)\n\n# Print the sorted list\nfor item in sorted_data:\n    print(item)\n```\n\n### Explanation\n\nIn this code:\n\n*   We define a custom key function `custom_sort_key` that takes a dictionary as an argument and returns a tuple containing the index of the key and the value.\n*   We use the `sorted()` function with the `key` argument set to our custom key function. This tells Python to sort the list based on the values returned by the custom key function.\n*   We apply this custom key function to each item in the list, which sorts the list based on the values of the specified key.\n\n### Optimizations\n\nIf your list of dictionaries is very large, sorting it can be inefficient. In such cases, you can use the `sorted()` function with a `key` function that returns a lambda function that calculates the index of the key. This approach is faster than using a list comprehension with `sorted()`.\n\n```python\ndef custom_sort_key(index, value):\n    \"\"\"\n    Custom key function to sort a dictionary based on a specific key.\n    \n    Args:\n        index (int): The index of the key.\n        value: The value to be used for sorting.\n    \n    Returns:\n        tuple: A tuple containing the index of the key and the value.\n    \"\"\"\n    return (index,"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:41:09.624906Z",
     "start_time": "2025-05-07T08:41:09.620436Z"
    }
   },
   "cell_type": "code",
   "source": "data[\"train\"][0]",
   "id": "347ea2e4fcc2b639",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:41:12.462138Z",
     "start_time": "2025-05-07T08:41:12.306828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def apply_chat_template(example):\n",
    "    answer = example['answers']['text']\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": example['question']},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return {\"prompt\": prompt}\n",
    "\n",
    "templated_dataset = data.map(apply_chat_template)"
   ],
   "id": "9b4588810dcdccb6",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:52:38.273991Z",
     "start_time": "2025-05-07T11:52:35.747470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "\n",
    "def apply_chat_template(\n",
    "        input_dataset: dict, tokeniser: PreTrainedTokenizerFast\n",
    ") -> dict:\n",
    "    \"\"\"Preprocess the input dataset to fit expected format.\n",
    "\n",
    "    See: https://huggingface.co/docs/trl/en/sft_trainer for details.\n",
    "    \"\"\"\n",
    "    answer = input_dataset['answers']['text']\n",
    "    message_template = [\n",
    "        {\"role\": \"system\", \"content\": input_dataset['context']},\n",
    "        {\"role\": \"user\", \"content\": input_dataset['question'][0]},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "    # messages = tokeniser.apply_chat_template(\n",
    "    #     message_template, tokenize=False, add_generation_prompt=True\n",
    "    # )\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "def apply_message_template(\n",
    "    input_dataset: dict\n",
    ") -> dict:\n",
    "    \"\"\"Preprocess the input dataset to fit expected format.\n",
    "\n",
    "    See: https://huggingface.co/docs/trl/en/sft_trainer for details.\n",
    "    \"\"\"\n",
    "    answer = input_dataset['answers']['text']\n",
    "    if isinstance(input_dataset['answers']['text'], list):\n",
    "        answer = input_dataset['answers']['text'][0]\n",
    "    message_template = [\n",
    "        {\"role\": \"system\", \"content\": input_dataset['context']},\n",
    "        {\"role\": \"user\", \"content\": input_dataset['question']},\n",
    "        {\"role\": \"assistant\", \"content\": answer}\n",
    "    ]\n",
    "    return {\"messages\": message_template}\n",
    "\n",
    "templated_dataset = data.map(apply_message_template)"
   ],
   "id": "3b33a32a01a8fa0a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 87599/87599 [00:02<00:00, 34745.72 examples/s]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:52:38.280245Z",
     "start_time": "2025-05-07T11:52:38.278144Z"
    }
   },
   "cell_type": "code",
   "source": "templated_dataset[0]",
   "id": "f7c648bcf8662811",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]},\n",
       " 'messages': [{'content': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       "   'role': 'system'},\n",
       "  {'content': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Saint Bernadette Soubirous', 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:58:33.078578Z",
     "start_time": "2025-05-07T11:58:33.064575Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "db8ae49fb6740633",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mbase_model\u001B[49m.config._name_or_path\n",
      "\u001B[31mNameError\u001B[39m: name 'base_model' is not defined"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:41:21.655863Z",
     "start_time": "2025-05-07T08:41:18.557176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenise the prompts\n",
    "def tokenize_function(example):\n",
    "    tokens = tokenizer(\n",
    "        example['prompt'],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    # Set padding token labels to -100 to ignore them in loss calculation\n",
    "    tokens['labels'] = [\n",
    "        -100 if token == tokenizer.pad_token_id else token for token in tokens['input_ids']\n",
    "    ]\n",
    "    return tokens\n",
    "\n",
    "tokenised_dataset = templated_dataset.map(tokenize_function)\n",
    "tokenised_dataset = tokenised_dataset.remove_columns([\"title\", \"context\", \"question\", \"answers\", \"prompt\"])"
   ],
   "id": "d16dcc2e5d39ea62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 10570/10570 [00:02<00:00, 3587.33 examples/s]\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T08:41:22.379579Z",
     "start_time": "2025-05-07T08:41:22.378038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # https://www.mercity.ai/blog-post/guide-to-fine-tuning-llms-with-lora-and-qlora\n",
    "# # https://huggingface.co/docs/diffusers/en/quantization/quanto\n",
    "# for name, module in model.named_modules(): # https://www.datacamp.com/tutorial/fine-tuning-llama-3-2\n",
    "#     print(f\"name: {name}\")\n",
    "#     print(f\"module: {module}\")\n"
   ],
   "id": "90175f498ffc230f",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:17:04.941939Z",
     "start_time": "2025-05-07T07:14:46.652530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "lora_base_model.train()\n",
    "training_args = SFTConfig(\n",
    "    output_dir = \"cp\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    gradient_accumulation_steps = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    eval_accumulation_steps = 8,\n",
    "    # optim = \"paged_adamw_32bit\",\n",
    "    save_steps = 10,\n",
    "    logging_steps = 10,\n",
    "    learning_rate = 5e-5,\n",
    "    max_grad_norm = 0.3,\n",
    "    max_steps = 50,\n",
    "    warmup_ratio = 0.03,\n",
    "    eval_strategy=\"steps\",\n",
    "    lr_scheduler_type = \"linear\",\n",
    ")\n",
    "trainer = SFTTrainer(\n",
    "    model=lora_base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_dataset[\"train\"],\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=lora_base_model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenised_dataset[\"train\"],\n",
    "#     eval_dataset=tokenised_dataset[\"validation\"],\n",
    "#     tokenizer=tokenizer)\n",
    "#\n",
    "# # Train the model\n",
    "# trainer.train()\n",
    "#\n",
    "# # Save the model and tokenizer\n",
    "# trainer.save_model(\"./fine-tuned-model\")\n",
    "# tokenizer.save_pretrained(\"./fine-tuned-model\")"
   ],
   "id": "c5e8e4cc98d8b052",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "/var/folders/r8/jzt55db94034zypvblzs5zk80000gn/T/ipykernel_73868/1483521713.py:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The following columns in the training set don't have a corresponding argument in `LlamaForCausalLM.forward` and have been ignored: id. If id are not expected by `LlamaForCausalLM.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 87,599\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 20\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 20\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8,760\n",
      "  Number of trainable parameters = 1,235,814,400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='8760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  40/8760 02:11 < 8:21:49, 0.29 it/s, Epoch 0.01/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     22\u001B[39m trainer = Trainer(\n\u001B[32m     23\u001B[39m     model=model,\n\u001B[32m     24\u001B[39m     args=training_args,\n\u001B[32m     25\u001B[39m     train_dataset=tokenised_dataset[\u001B[33m\"\u001B[39m\u001B[33mtrain\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     26\u001B[39m     eval_dataset=tokenised_dataset[\u001B[33m\"\u001B[39m\u001B[33mvalidation\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     27\u001B[39m     tokenizer=tokenizer)\n\u001B[32m     29\u001B[39m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[38;5;66;03m# Save the model and tokenizer\u001B[39;00m\n\u001B[32m     33\u001B[39m trainer.save_model(\u001B[33m\"\u001B[39m\u001B[33m./fine-tuned-model\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/transformers/trainer.py:2245\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2243\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2244\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2245\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2246\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2247\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2248\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2249\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2250\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/transformers/trainer.py:2560\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2553\u001B[39m context = (\n\u001B[32m   2554\u001B[39m     functools.partial(\u001B[38;5;28mself\u001B[39m.accelerator.no_sync, model=model)\n\u001B[32m   2555\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m i != \u001B[38;5;28mlen\u001B[39m(batch_samples) - \u001B[32m1\u001B[39m\n\u001B[32m   2556\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001B[32m   2557\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m contextlib.nullcontext\n\u001B[32m   2558\u001B[39m )\n\u001B[32m   2559\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[32m-> \u001B[39m\u001B[32m2560\u001B[39m     tr_loss_step = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_items_in_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2562\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2563\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   2564\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[32m   2565\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m torch.isinf(tr_loss_step))\n\u001B[32m   2566\u001B[39m ):\n\u001B[32m   2567\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   2568\u001B[39m     tr_loss = tr_loss + tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/transformers/trainer.py:3782\u001B[39m, in \u001B[36mTrainer.training_step\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m   3779\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001B[32m   3780\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mscale_wrt_gas\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3782\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maccelerator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3784\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m loss.detach()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/accelerate/accelerator.py:2454\u001B[39m, in \u001B[36mAccelerator.backward\u001B[39m\u001B[34m(self, loss, **kwargs)\u001B[39m\n\u001B[32m   2452\u001B[39m     \u001B[38;5;28mself\u001B[39m.lomo_backward(loss, learning_rate)\n\u001B[32m   2453\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2454\u001B[39m     \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/PersonalProjects.nosync/tomorro_llm_tech/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:20:03.370872Z",
     "start_time": "2025-05-07T07:20:03.283424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "path = \"raw_data/ConvFinQA/train.json\"\n",
    "with open(path, \"r\") as file:\n",
    "    data = json.load(file)"
   ],
   "id": "ef48d34bb81dcb54",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T07:20:13.480480Z",
     "start_time": "2025-05-07T07:20:13.477732Z"
    }
   },
   "cell_type": "code",
   "source": "data[0]",
   "id": "5a755aafa8aa9331",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pre_text': ['26 | 2009 annual report in fiscal 2008 , revenues in the credit union systems and services business segment increased 14% ( 14 % ) from fiscal 2007 .',\n",
       "  'all revenue components within the segment experienced growth during fiscal 2008 .',\n",
       "  'license revenue generated the largest dollar growth in revenue as episys ae , our flagship core processing system aimed at larger credit unions , experienced strong sales throughout the year .',\n",
       "  'support and service revenue , which is the largest component of total revenues for the credit union segment , experienced 34 percent growth in eft support and 10 percent growth in in-house support .',\n",
       "  'gross profit in this business segment increased $ 9344 in fiscal 2008 compared to fiscal 2007 , due primarily to the increase in license revenue , which carries the highest margins .',\n",
       "  'liquidity and capital resources we have historically generated positive cash flow from operations and have generally used funds generated from operations and short-term borrowings on our revolving credit facility to meet capital requirements .',\n",
       "  'we expect this trend to continue in the future .',\n",
       "  'the company 2019s cash and cash equivalents increased to $ 118251 at june 30 , 2009 from $ 65565 at june 30 , 2008 .',\n",
       "  'the following table summarizes net cash from operating activities in the statement of cash flows : 2009 2008 2007 .'],\n",
       " 'post_text': ['year ended june 30 , cash provided by operations increased $ 25587 to $ 206588 for the fiscal year ended june 30 , 2009 as compared to $ 181001 for the fiscal year ended june 30 , 2008 .',\n",
       "  'this increase is primarily attributable to a decrease in receivables compared to the same period a year ago of $ 21214 .',\n",
       "  'this decrease is largely the result of fiscal 2010 annual software maintenance billings being provided to customers earlier than in the prior year , which allowed more cash to be collected before the end of the fiscal year than in previous years .',\n",
       "  'further , we collected more cash overall related to revenues that will be recognized in subsequent periods in the current year than in fiscal 2008 .',\n",
       "  'cash used in investing activities for the fiscal year ended june 2009 was $ 59227 and includes $ 3027 in contingent consideration paid on prior years 2019 acquisitions .',\n",
       "  'cash used in investing activities for the fiscal year ended june 2008 was $ 102148 and includes payments for acquisitions of $ 48109 , plus $ 1215 in contingent consideration paid on prior years 2019 acquisitions .',\n",
       "  'capital expenditures for fiscal 2009 were $ 31562 compared to $ 31105 for fiscal 2008 .',\n",
       "  'cash used for software development in fiscal 2009 was $ 24684 compared to $ 23736 during the prior year .',\n",
       "  'net cash used in financing activities for the current fiscal year was $ 94675 and includes the repurchase of 3106 shares of our common stock for $ 58405 , the payment of dividends of $ 26903 and $ 13489 net repayment on our revolving credit facilities .',\n",
       "  'cash used in financing activities was partially offset by proceeds of $ 3773 from the exercise of stock options and the sale of common stock ( through the employee stock purchase plan ) and $ 348 excess tax benefits from stock option exercises .',\n",
       "  'during fiscal 2008 , net cash used in financing activities for the fiscal year was $ 101905 and includes the repurchase of 4200 shares of our common stock for $ 100996 , the payment of dividends of $ 24683 and $ 429 net repayment on our revolving credit facilities .',\n",
       "  'cash used in financing activities was partially offset by proceeds of $ 20394 from the exercise of stock options and the sale of common stock and $ 3809 excess tax benefits from stock option exercises .',\n",
       "  'beginning during fiscal 2008 , us financial markets and many of the largest us financial institutions have been shaken by negative developments in the home mortgage industry and the mortgage markets , and particularly the markets for subprime mortgage-backed securities .',\n",
       "  'since that time , these and other such developments have resulted in a broad , global economic downturn .',\n",
       "  'while we , as is the case with most companies , have experienced the effects of this downturn , we have not experienced any significant issues with our current collection efforts , and we believe that any future impact to our liquidity will be minimized by cash generated by recurring sources of revenue and due to our access to available lines of credit. .'],\n",
       " 'filename': 'JKHY/2009/page_28.pdf',\n",
       " 'table_ori': [['', 'Year ended June 30, 2009'],\n",
       "  ['2008', '2007'],\n",
       "  ['Net income', '$103,102', '$104,222', '$104,681'],\n",
       "  ['Non-cash expenses', '74,397', '70,420', '56,348'],\n",
       "  ['Change in receivables', '21,214', '(2,913)', '(28,853)'],\n",
       "  ['Change in deferred revenue', '21,943', '5,100', '24,576'],\n",
       "  ['Change in other assets and liabilities', '(14,068)', '4,172', '17,495'],\n",
       "  ['Net cash from operating activities', '$206,588', '$181,001', '$174,247']],\n",
       " 'table': [['2008',\n",
       "   'year ended june 30 2009 2008',\n",
       "   'year ended june 30 2009 2008',\n",
       "   'year ended june 30 2009'],\n",
       "  ['net income', '$ 103102', '$ 104222', '$ 104681'],\n",
       "  ['non-cash expenses', '74397', '70420', '56348'],\n",
       "  ['change in receivables', '21214', '-2913 ( 2913 )', '-28853 ( 28853 )'],\n",
       "  ['change in deferred revenue', '21943', '5100', '24576'],\n",
       "  ['change in other assets and liabilities',\n",
       "   '-14068 ( 14068 )',\n",
       "   '4172',\n",
       "   '17495'],\n",
       "  ['net cash from operating activities', '$ 206588', '$ 181001', '$ 174247']],\n",
       " 'qa': {'question': 'what was the percentage change in the net cash from operating activities from 2008 to 2009',\n",
       "  'answer': '14.1%',\n",
       "  'explanation': '',\n",
       "  'ann_table_rows': [6],\n",
       "  'ann_text_rows': [],\n",
       "  'steps': [{'op': 'minus2-1',\n",
       "    'arg1': '206588',\n",
       "    'arg2': '181001',\n",
       "    'res': '25587'},\n",
       "   {'op': 'divide2-2', 'arg1': '#0', 'arg2': '181001', 'res': '14.1%'}],\n",
       "  'program': 'subtract(206588, 181001), divide(#0, 181001)',\n",
       "  'gold_inds': {'table_6': '2008 the net cash from operating activities of year ended june 30 2009 2008 is $ 206588 ; the net cash from operating activities of year ended june 30 2009 2008 is $ 181001 ; the net cash from operating activities of year ended june 30 2009 is $ 174247 ;'},\n",
       "  'exe_ans': 0.14136,\n",
       "  'program_re': 'divide(subtract(206588, 181001), 181001)'},\n",
       " 'id': 'Single_JKHY/2009/page_28.pdf-3',\n",
       " 'annotation': {'amt_table': \"<table class='wikitable'><tr><td>1</td><td>2008</td><td>year ended june 30 2009 2008</td><td>year ended june 30 2009 2008</td><td>year ended june 30 2009</td></tr><tr><td>2</td><td>net income</td><td>$ 103102</td><td>$ 104222</td><td>$ 104681</td></tr><tr><td>3</td><td>non-cash expenses</td><td>74397</td><td>70420</td><td>56348</td></tr><tr><td>4</td><td>change in receivables</td><td>21214</td><td>-2913 ( 2913 )</td><td>-28853 ( 28853 )</td></tr><tr><td>5</td><td>change in deferred revenue</td><td>21943</td><td>5100</td><td>24576</td></tr><tr><td>6</td><td>change in other assets and liabilities</td><td>-14068 ( 14068 )</td><td>4172</td><td>17495</td></tr><tr><td>7</td><td>net cash from operating activities</td><td>$ 206588</td><td>$ 181001</td><td>$ 174247</td></tr></table>\",\n",
       "  'amt_pre_text': '26 | 2009 annual report in fiscal 2008 , revenues in the credit union systems and services business segment increased 14% ( 14 % ) from fiscal 2007 . all revenue components within the segment experienced growth during fiscal 2008 . license revenue generated the largest dollar growth in revenue as episys ae , our flagship core processing system aimed at larger credit unions , experienced strong sales throughout the year . support and service revenue , which is the largest component of total revenues for the credit union segment , experienced 34 percent growth in eft support and 10 percent growth in in-house support . gross profit in this business segment increased $ 9344 in fiscal 2008 compared to fiscal 2007 , due primarily to the increase in license revenue , which carries the highest margins . liquidity and capital resources we have historically generated positive cash flow from operations and have generally used funds generated from operations and short-term borrowings on our revolving credit facility to meet capital requirements . we expect this trend to continue in the future . the company 2019s cash and cash equivalents increased to $ 118251 at june 30 , 2009 from $ 65565 at june 30 , 2008 . the following table summarizes net cash from operating activities in the statement of cash flows : 2009 2008 2007 .',\n",
       "  'amt_post_text': 'year ended june 30 , cash provided by operations increased $ 25587 to $ 206588 for the fiscal year ended june 30 , 2009 as compared to $ 181001 for the fiscal year ended june 30 , 2008 . this increase is primarily attributable to a decrease in receivables compared to the same period a year ago of $ 21214 . this decrease is largely the result of fiscal 2010 annual software maintenance billings being provided to customers earlier than in the prior year , which allowed more cash to be collected before the end of the fiscal year than in previous years . further , we collected more cash overall related to revenues that will be recognized in subsequent periods in the current year than in fiscal 2008 . cash used in investing activities for the fiscal year ended june 2009 was $ 59227 and includes $ 3027 in contingent consideration paid on prior years 2019 acquisitions . cash used in investing activities for the fiscal year ended june 2008 was $ 102148 and includes payments for acquisitions of $ 48109 , plus $ 1215 in contingent consideration paid on prior years 2019 acquisitions . capital expenditures for fiscal 2009 were $ 31562 compared to $ 31105 for fiscal 2008 . cash used for software development in fiscal 2009 was $ 24684 compared to $ 23736 during the prior year . net cash used in financing activities for the current fiscal year was $ 94675 and includes the repurchase of 3106 shares of our common stock for $ 58405 , the payment of dividends of $ 26903 and $ 13489 net repayment on our revolving credit facilities . cash used in financing activities was partially offset by proceeds of $ 3773 from the exercise of stock options and the sale of common stock ( through the employee stock purchase plan ) and $ 348 excess tax benefits from stock option exercises . during fiscal 2008 , net cash used in financing activities for the fiscal year was $ 101905 and includes the repurchase of 4200 shares of our common stock for $ 100996 , the payment of dividends of $ 24683 and $ 429 net repayment on our revolving credit facilities . cash used in financing activities was partially offset by proceeds of $ 20394 from the exercise of stock options and the sale of common stock and $ 3809 excess tax benefits from stock option exercises . beginning during fiscal 2008 , us financial markets and many of the largest us financial institutions have been shaken by negative developments in the home mortgage industry and the mortgage markets , and particularly the markets for subprime mortgage-backed securities . since that time , these and other such developments have resulted in a broad , global economic downturn . while we , as is the case with most companies , have experienced the effects of this downturn , we have not experienced any significant issues with our current collection efforts , and we believe that any future impact to our liquidity will be minimized by cash generated by recurring sources of revenue and due to our access to available lines of credit. .',\n",
       "  'original_program': 'subtract(206588, 181001), divide(A0, 181001)',\n",
       "  'step_list': ['Ask for number 206588',\n",
       "   'Ask for number 181001',\n",
       "   'subtract(206588, 181001)',\n",
       "   'divide(A0, 181001)'],\n",
       "  'answer_list': ['206588', '181001', 'A0', 'A1'],\n",
       "  'dialogue_break': ['what is the net cash from operating activities in 2009?',\n",
       "   'what about in 2008?',\n",
       "   'what is the difference?',\n",
       "   'what percentage change does this represent?'],\n",
       "  'turn_program_ori': ['206588',\n",
       "   '181001',\n",
       "   'subtract(206588, 181001)',\n",
       "   'subtract(206588, 181001), divide(#0, 181001)'],\n",
       "  'dialogue_break_ori': ['what is the net cash from operating activities in 2009?',\n",
       "   'what about in 2008?',\n",
       "   'what is the difference?',\n",
       "   'what percentage change does this represent?'],\n",
       "  'turn_program': ['206588',\n",
       "   '181001',\n",
       "   'subtract(206588, 181001)',\n",
       "   'subtract(206588, 181001), divide(#0, 181001)'],\n",
       "  'qa_split': [0, 0, 0, 0],\n",
       "  'exe_ans_list': [206588.0, 181001.0, 25587.0, 0.14136]}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de37e09ac2478192"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
